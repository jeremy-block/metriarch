{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Merge the Transition probability data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>DataExploreCounts</th>\n",
       "      <th>VisualExploreCounts</th>\n",
       "      <th>InsightCounts</th>\n",
       "      <th>TheorizeCounts</th>\n",
       "      <th>DiscoveryCounts</th>\n",
       "      <th>NewIdeaCounts</th>\n",
       "      <th>OrganizeCounts</th>\n",
       "      <th>PatternRecognitionCounts</th>\n",
       "      <th>TrailCounts</th>\n",
       "      <th>...</th>\n",
       "      <th>DataExploreUnusual</th>\n",
       "      <th>VisualExploreUnusual</th>\n",
       "      <th>InsightUnusual</th>\n",
       "      <th>TheorizeUnusual</th>\n",
       "      <th>DiscoveryUnusual</th>\n",
       "      <th>NewIdeaUnusual</th>\n",
       "      <th>OrganizeUnusual</th>\n",
       "      <th>PatternRecognitionUnusual</th>\n",
       "      <th>TrailUnusual</th>\n",
       "      <th>TotalUnusual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arms_P1_InteractionsLogs.json</td>\n",
       "      <td>204.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.284738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arms_P2_InteractionsLogs.json</td>\n",
       "      <td>192.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.171729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arms_P3_InteractionsLogs.json</td>\n",
       "      <td>468.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.327957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.255302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arms_P4_InteractionsLogs.json</td>\n",
       "      <td>271.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.353293</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122302</td>\n",
       "      <td>0.217210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arms_P5_InteractionsLogs.json</td>\n",
       "      <td>310.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141935</td>\n",
       "      <td>0.117073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.218978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        FileName  DataExploreCounts  VisualExploreCounts  \\\n",
       "0  Arms_P1_InteractionsLogs.json              204.0                144.0   \n",
       "1  Arms_P2_InteractionsLogs.json              192.0                255.0   \n",
       "2  Arms_P3_InteractionsLogs.json              468.0                163.0   \n",
       "3  Arms_P4_InteractionsLogs.json              271.0                196.0   \n",
       "4  Arms_P5_InteractionsLogs.json              310.0                205.0   \n",
       "\n",
       "   InsightCounts  TheorizeCounts  DiscoveryCounts  NewIdeaCounts  \\\n",
       "0           49.0           101.0             80.0           67.0   \n",
       "1           15.0           115.0             50.0           41.0   \n",
       "2           29.0           186.0             68.0           80.0   \n",
       "3           32.0           134.0            167.0          161.0   \n",
       "4            2.0           149.0             29.0           19.0   \n",
       "\n",
       "   OrganizeCounts  PatternRecognitionCounts  TrailCounts  ...  \\\n",
       "0            67.0                      52.0        114.0  ...   \n",
       "1            37.0                      27.0        124.0  ...   \n",
       "2            24.0                      33.0        175.0  ...   \n",
       "3            51.0                      46.0        139.0  ...   \n",
       "4            48.0                      37.0        160.0  ...   \n",
       "\n",
       "   DataExploreUnusual  VisualExploreUnusual  InsightUnusual  TheorizeUnusual  \\\n",
       "0            0.254902              0.000000        0.306122         0.495050   \n",
       "1            0.114583              0.000000        0.866667         0.043478   \n",
       "2            0.170940              0.000000        0.241379         0.327957   \n",
       "3            0.147601              0.000000        0.375000         0.305970   \n",
       "4            0.141935              0.117073        1.000000         0.194631   \n",
       "\n",
       "   DiscoveryUnusual  NewIdeaUnusual  OrganizeUnusual  \\\n",
       "0          0.450000        0.477612         0.134328   \n",
       "1          0.380000        0.317073         0.081081   \n",
       "2          1.000000        0.162500         0.458333   \n",
       "3          0.353293        0.198758         0.254902   \n",
       "4          1.000000        1.000000         0.000000   \n",
       "\n",
       "   PatternRecognitionUnusual  TrailUnusual  TotalUnusual  \n",
       "0                        0.5      0.263158      0.284738  \n",
       "1                        1.0      0.362903      0.171729  \n",
       "2                        1.0      0.228571      0.255302  \n",
       "3                        1.0      0.122302      0.217210  \n",
       "4                        1.0      0.162500      0.218978  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names to merge\n",
    "csv_files = [\"transitions_calulations_dataset1.csv\", \"transitions_calulations_dataset2.csv\", \"transitions_calulations_dataset3.csv\"]  # Replace with your file names\n",
    "\n",
    "# Name of the common column used for merging\n",
    "merge_column_name = \"FileName\"  # Replace with the desired column name\n",
    "\n",
    "# Initialize an empty DataFrame as the base\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and merge\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # If it's the first file, set it as the base DataFrame\n",
    "    if merged_data.empty:\n",
    "        merged_data = df\n",
    "    else:\n",
    "        # Merge the current DataFrame with the base DataFrame based on the common column\n",
    "        merged_data = merged_data.merge(df, how=\"outer\")\n",
    "\n",
    "# Fill missing values with appropriate values (e.g., NaN or a specific value)\n",
    "merged_data = merged_data.fillna(\"\")\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv(\"temp1_merged_transitions_data.csv\", index=False)\n",
    "\n",
    "# Display the merged data\n",
    "merged_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merge the unusual Transition types with the rest of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>section</th>\n",
       "      <th>total_think_aloud_count</th>\n",
       "      <th>total_search_count</th>\n",
       "      <th>total_topic_change_count</th>\n",
       "      <th>total_mouse_hover_count</th>\n",
       "      <th>total_draging_count</th>\n",
       "      <th>total_open-doc_count</th>\n",
       "      <th>total_reading_count</th>\n",
       "      <th>total_highlight_count</th>\n",
       "      <th>...</th>\n",
       "      <th>DataExploreUnusual</th>\n",
       "      <th>VisualExploreUnusual</th>\n",
       "      <th>InsightUnusual</th>\n",
       "      <th>TheorizeUnusual</th>\n",
       "      <th>DiscoveryUnusual</th>\n",
       "      <th>NewIdeaUnusual</th>\n",
       "      <th>OrganizeUnusual</th>\n",
       "      <th>PatternRecognitionUnusual</th>\n",
       "      <th>TrailUnusual</th>\n",
       "      <th>TotalUnusual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arms_P1_InteractionsLogs.json</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>137.0</td>\n",
       "      <td>82</td>\n",
       "      <td>10.0</td>\n",
       "      <td>143.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>134</td>\n",
       "      <td>159.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.49505</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.284738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arms_P2_InteractionsLogs.json</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>69.0</td>\n",
       "      <td>27</td>\n",
       "      <td>6.0</td>\n",
       "      <td>275.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>91</td>\n",
       "      <td>233.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.171729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arms_P3_InteractionsLogs.json</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>78.0</td>\n",
       "      <td>46</td>\n",
       "      <td>15.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>207.0</td>\n",
       "      <td>140</td>\n",
       "      <td>522.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17094</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.327957</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.255302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arms_P4_InteractionsLogs.json</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>76</td>\n",
       "      <td>10.0</td>\n",
       "      <td>152.0</td>\n",
       "      <td>229.0</td>\n",
       "      <td>149</td>\n",
       "      <td>337.0</td>\n",
       "      <td>141.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.30597</td>\n",
       "      <td>0.353293</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122302</td>\n",
       "      <td>0.21721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arms_P5_InteractionsLogs.json</td>\n",
       "      <td>dataset1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>264.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>239</td>\n",
       "      <td>173.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141935</td>\n",
       "      <td>0.117073</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.218978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 127 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         session   section total_think_aloud_count  \\\n",
       "0  Arms_P1_InteractionsLogs.json  dataset1                   137.0   \n",
       "1  Arms_P2_InteractionsLogs.json  dataset1                    69.0   \n",
       "2  Arms_P3_InteractionsLogs.json  dataset1                    78.0   \n",
       "3  Arms_P4_InteractionsLogs.json  dataset1                    74.0   \n",
       "4  Arms_P5_InteractionsLogs.json  dataset1                    32.0   \n",
       "\n",
       "   total_search_count total_topic_change_count total_mouse_hover_count  \\\n",
       "0                  82                     10.0                   143.0   \n",
       "1                  27                      6.0                   275.0   \n",
       "2                  46                     15.0                   167.0   \n",
       "3                  76                     10.0                   152.0   \n",
       "4                  66                     11.0                   264.0   \n",
       "\n",
       "  total_draging_count  total_open-doc_count total_reading_count  \\\n",
       "0               169.0                   134               159.0   \n",
       "1               132.0                    91               233.0   \n",
       "2               207.0                   140               522.0   \n",
       "3               229.0                   149               337.0   \n",
       "4               139.0                   239               173.0   \n",
       "\n",
       "  total_highlight_count  ... DataExploreUnusual VisualExploreUnusual  \\\n",
       "0                  21.0  ...           0.254902                  0.0   \n",
       "1                   8.0  ...           0.114583                  0.0   \n",
       "2                   7.0  ...            0.17094                  0.0   \n",
       "3                 141.0  ...           0.147601                  0.0   \n",
       "4                   1.0  ...           0.141935             0.117073   \n",
       "\n",
       "  InsightUnusual TheorizeUnusual  DiscoveryUnusual NewIdeaUnusual  \\\n",
       "0       0.306122         0.49505              0.45       0.477612   \n",
       "1       0.866667        0.043478              0.38       0.317073   \n",
       "2       0.241379        0.327957               1.0         0.1625   \n",
       "3          0.375         0.30597          0.353293       0.198758   \n",
       "4            1.0        0.194631               1.0            1.0   \n",
       "\n",
       "  OrganizeUnusual PatternRecognitionUnusual  TrailUnusual TotalUnusual  \n",
       "0        0.134328                       0.5      0.263158     0.284738  \n",
       "1        0.081081                       1.0      0.362903     0.171729  \n",
       "2        0.458333                       1.0      0.228571     0.255302  \n",
       "3        0.254902                       1.0      0.122302      0.21721  \n",
       "4             0.0                       1.0        0.1625     0.218978  \n",
       "\n",
       "[5 rows x 127 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names to merge\n",
    "csv_files = [\n",
    "    \"./prov-metrics-20231027.csv\",\n",
    "    \"temp1_merged_transitions_data.csv\",\n",
    "]  # Replace with your 2 file names\n",
    "\n",
    "# Name of the common column used for merging\n",
    "left_column_name = \"session\"  # Replace with the desired column names\n",
    "right_column_name = \"FileName\"\n",
    "\n",
    "# Initialize an empty DataFrame as the base\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and merge\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # If it's the first file, set it as the base DataFrame\n",
    "    if merged_data.empty:\n",
    "        merged_data = df\n",
    "    else:\n",
    "        # Merge the current DataFrame with the base DataFrame based on the common column\n",
    "        merged_data = merged_data.merge(\n",
    "            df, left_on=left_column_name, right_on=right_column_name, how=\"outer\"\n",
    "        )\n",
    "        merged_data.drop(\n",
    "            right_column_name, axis=1, inplace=True\n",
    "        )  # Remove right column since we have merged this.\n",
    "\n",
    "# Fill missing values with appropriate values (e.g., NaN or a specific value)\n",
    "merged_data = merged_data.fillna(\"0\")\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv(\"temp2_all_merged_data.csv\", index=False)\n",
    "\n",
    "# Display the merged data\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.a. Modify or create a Config File to include any newly merged column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_csv_file, input_json_file, output_json_file):\n",
    "    # Initialize an empty dictionary to store the JSON data\n",
    "    json_data = {}\n",
    "\n",
    "    # Read the existing JSON data from the output file if it exists\n",
    "    try:\n",
    "        with open(input_json_file, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Read the CSV file\n",
    "    with open(input_csv_file, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "        # Iterate through the columns in the CSV file\n",
    "        for column_name in csv_reader.fieldnames:\n",
    "            # Check if the column name already exists in the JSON data\n",
    "            if column_name not in json_data:\n",
    "                json_data[f'{column_name}'] = {\n",
    "                    \"name\": column_name,\n",
    "                    \"unit\": \"\",\n",
    "                    \"description\": f\"a_written_description for {column_name}\",\n",
    "                    \"majorTicks\": 4,\n",
    "                    \"minorTicks\": 1,\n",
    "                    \"places\": 0\n",
    "                }\n",
    "\n",
    "    # Write the JSON data to the output file\n",
    "    with open(output_json_file, 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "# Example usage:\n",
    "input_csv_file = 'temp2_all_merged_data.csv'\n",
    "input_json_file = 'datasetAll.json'\n",
    "output_json_file = input_json_file\n",
    "csv_to_json(input_csv_file, input_json_file, output_json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Drop columns with limited meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "127 Column names in the CSV file:\n",
      "\"session\",\n",
      "\"section\",\n",
      "\"total_think_aloud_count\",\n",
      "\"total_search_count\",\n",
      "\"total_topic_change_count\",\n",
      "\"total_mouse_hover_count\",\n",
      "\"total_draging_count\",\n",
      "\"total_open-doc_count\",\n",
      "\"total_reading_count\",\n",
      "\"total_highlight_count\",\n",
      "\"total_connection_count\",\n",
      "\"total_create_note_count\",\n",
      "\"total_add_note_count\",\n",
      "\"think_aloud_ratio\",\n",
      "\"search_ratio\",\n",
      "\"topic_change_ratio\",\n",
      "\"mouse_hover_ratio\",\n",
      "\"draging_ratio\",\n",
      "\"open-doc_ratio\",\n",
      "\"reading_ratio\",\n",
      "\"highlight_ratio\",\n",
      "\"connection_ratio\",\n",
      "\"create_note_ratio\",\n",
      "\"add_note_ratio\",\n",
      "\"total_interaction_count\",\n",
      "\"total_duration\",\n",
      "\"repeat_searches\",\n",
      "\"prop_repeat_searches\",\n",
      "\"search_term_similarity\",\n",
      "\"search_time_std_dev\",\n",
      "\"search_open_overlap\",\n",
      "\"search_term_efficiency\",\n",
      "\"total_initialized_count\",\n",
      "\"total_query_results_count\",\n",
      "\"total_read_count\",\n",
      "\"total_playaudiofileinnewwindow_count\",\n",
      "\"total_collapse_count\",\n",
      "\"total_find_count\",\n",
      "\"total_dispositionupdated_count\",\n",
      "\"total_noteupdated_count\",\n",
      "\"total_listening_count\",\n",
      "\"total_createdocumentbucket_count\",\n",
      "\"total_addtodocumentbucket_count\",\n",
      "\"total_removefromdocumentbucket_count\",\n",
      "\"total_tabs_to_questions_count\",\n",
      "\"total_tabs_to_cap_count\",\n",
      "\"total_edit_document_bucket_count\",\n",
      "\"total_loaddocumentlist_count\",\n",
      "\"total_show_count\",\n",
      "\"total_getdocuments_count\",\n",
      "\"total_answers_question_count\",\n",
      "\"total_tabs_to_supplementary_count\",\n",
      "\"total_tabs_to_bundle_count\",\n",
      "\"total_reads_count\",\n",
      "\"total_tabs_to_abreviations_count\",\n",
      "\"total_answers_confidence_count\",\n",
      "\"total_tabs_to_bundles_count\",\n",
      "\"total_answer_count\",\n",
      "\"total_initiate_count\",\n",
      "\"total_custom_count\",\n",
      "\"initialized_ratio\",\n",
      "\"query_results_ratio\",\n",
      "\"read_ratio\",\n",
      "\"playaudiofileinnewwindow_ratio\",\n",
      "\"collapse_ratio\",\n",
      "\"find_ratio\",\n",
      "\"dispositionupdated_ratio\",\n",
      "\"noteupdated_ratio\",\n",
      "\"listening_ratio\",\n",
      "\"createdocumentbucket_ratio\",\n",
      "\"addtodocumentbucket_ratio\",\n",
      "\"removefromdocumentbucket_ratio\",\n",
      "\"tabs_to_questions_ratio\",\n",
      "\"tabs_to_cap_ratio\",\n",
      "\"edit_document_bucket_ratio\",\n",
      "\"loaddocumentlist_ratio\",\n",
      "\"show_ratio\",\n",
      "\"getdocuments_ratio\",\n",
      "\"answers_question_ratio\",\n",
      "\"tabs_to_supplementary_ratio\",\n",
      "\"tabs_to_bundle_ratio\",\n",
      "\"reads_ratio\",\n",
      "\"tabs_to_abreviations_ratio\",\n",
      "\"answers_confidence_ratio\",\n",
      "\"tabs_to_bundles_ratio\",\n",
      "\"answer_ratio\",\n",
      "\"initiate_ratio\",\n",
      "\"custom_ratio\",\n",
      "\"total_switch_count\",\n",
      "\"total_discover_count\",\n",
      "\"total_save_count\",\n",
      "\"total_revisit_count\",\n",
      "\"total_assign_count\",\n",
      "\"switch_ratio\",\n",
      "\"discover_ratio\",\n",
      "\"save_ratio\",\n",
      "\"revisit_ratio\",\n",
      "\"assign_ratio\",\n",
      "\"DataExploreCounts\",\n",
      "\"VisualExploreCounts\",\n",
      "\"InsightCounts\",\n",
      "\"TheorizeCounts\",\n",
      "\"DiscoveryCounts\",\n",
      "\"NewIdeaCounts\",\n",
      "\"OrganizeCounts\",\n",
      "\"PatternRecognitionCounts\",\n",
      "\"TrailCounts\",\n",
      "\"DataExploreUsual\",\n",
      "\"VisualExploreUsual\",\n",
      "\"InsightUsual\",\n",
      "\"TheorizeUsual\",\n",
      "\"DiscoveryUsual\",\n",
      "\"NewIdeaUsual\",\n",
      "\"OrganizeUsual\",\n",
      "\"PatternRecognitionUsual\",\n",
      "\"TrailUsual\",\n",
      "\"TotalUsual\",\n",
      "\"DataExploreUnusual\",\n",
      "\"VisualExploreUnusual\",\n",
      "\"InsightUnusual\",\n",
      "\"TheorizeUnusual\",\n",
      "\"DiscoveryUnusual\",\n",
      "\"NewIdeaUnusual\",\n",
      "\"OrganizeUnusual\",\n",
      "\"PatternRecognitionUnusual\",\n",
      "\"TrailUnusual\",\n",
      "\"TotalUnusual\",\n"
     ]
    }
   ],
   "source": [
    "if 'pd' not in globals():\n",
    "    import pandas as pd\n",
    "\n",
    "# get list of column names\n",
    "def get_column_names_from_csv(csv_file_path):\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Get the column names as a list\n",
    "        column_names = df.columns.tolist()\n",
    "\n",
    "        return column_names\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "csv_file_path = \"temp2_all_merged_data.csv\"  # Replace with the path to your CSV file\n",
    "column_names = get_column_names_from_csv(csv_file_path)\n",
    "\n",
    "if column_names is not None:\n",
    "    print(len(column_names), \"Column names in the CSV file:\")\n",
    "    for name in column_names:\n",
    "        print(f\"\\\"{name}\\\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to remove 79 colums\n",
      "Success, output dimentions of the dataset: (46, 48)\n",
      "output to temp3_output_csv_file.csv. Don't forget to rename to 'datasetAll.csv'\n"
     ]
    }
   ],
   "source": [
    "if \"pd\" not in globals():\n",
    "    import pandas as pd\n",
    "\n",
    "# Define the list of columns you want to remove\n",
    "columns_to_remove = [\n",
    "    \"total_draging_count\",\n",
    "    \"total_reading_count\",\n",
    "    \"total_highlight_count\",\n",
    "    \"total_connection_count\",\n",
    "    \"total_create_note_count\",\n",
    "    \"total_add_note_count\",\n",
    "    \"mouse_hover_ratio\",\n",
    "    \"draging_ratio\",\n",
    "    \"reading_ratio\",\n",
    "    \"highlight_ratio\",\n",
    "    \"connection_ratio\",\n",
    "    \"create_note_ratio\",\n",
    "    \"add_note_ratio\",\n",
    "    \"total_initialized_count\",\n",
    "    \"total_query_results_count\",\n",
    "    \"total_read_count\",\n",
    "    \"total_playaudiofileinnewwindow_count\",\n",
    "    \"total_collapse_count\",\n",
    "    \"total_find_count\",\n",
    "    \"total_dispositionupdated_count\",\n",
    "    \"total_noteupdated_count\",\n",
    "    \"total_listening_count\",\n",
    "    \"total_createdocumentbucket_count\",\n",
    "    \"total_addtodocumentbucket_count\",\n",
    "    \"total_removefromdocumentbucket_count\",\n",
    "    \"total_tabs_to_questions_count\",\n",
    "    \"total_tabs_to_cap_count\",\n",
    "    \"total_edit_document_bucket_count\",\n",
    "    \"total_loaddocumentlist_count\",\n",
    "    \"total_show_count\",\n",
    "    \"total_getdocuments_count\",\n",
    "    \"total_answers_question_count\",\n",
    "    \"total_tabs_to_supplementary_count\",\n",
    "    \"total_tabs_to_bundle_count\",\n",
    "    \"total_reads_count\",\n",
    "    \"total_tabs_to_abreviations_count\",\n",
    "    \"total_answers_confidence_count\",\n",
    "    \"total_tabs_to_bundles_count\",\n",
    "    \"total_answer_count\",\n",
    "    \"total_initiate_count\",\n",
    "    \"total_custom_count\",\n",
    "    \"initialized_ratio\",\n",
    "    \"query_results_ratio\",\n",
    "    \"read_ratio\",\n",
    "    \"playaudiofileinnewwindow_ratio\",\n",
    "    \"collapse_ratio\",\n",
    "    \"find_ratio\",\n",
    "    \"dispositionupdated_ratio\",\n",
    "    \"noteupdated_ratio\",\n",
    "    \"listening_ratio\",\n",
    "    \"createdocumentbucket_ratio\",\n",
    "    \"addtodocumentbucket_ratio\",\n",
    "    \"removefromdocumentbucket_ratio\",\n",
    "    \"tabs_to_questions_ratio\",\n",
    "    \"tabs_to_cap_ratio\",\n",
    "    \"edit_document_bucket_ratio\",\n",
    "    \"loaddocumentlist_ratio\",\n",
    "    \"show_ratio\",\n",
    "    \"getdocuments_ratio\",\n",
    "    \"answers_question_ratio\",\n",
    "    \"tabs_to_supplementary_ratio\",\n",
    "    \"tabs_to_bundle_ratio\",\n",
    "    \"reads_ratio\",\n",
    "    \"tabs_to_abreviations_ratio\",\n",
    "    \"answers_confidence_ratio\",\n",
    "    \"tabs_to_bundles_ratio\",\n",
    "    \"answer_ratio\",\n",
    "    \"initiate_ratio\",\n",
    "    \"custom_ratio\",\n",
    "    \"total_switch_count\",\n",
    "    \"total_discover_count\",\n",
    "    \"total_save_count\",\n",
    "    \"total_revisit_count\",\n",
    "    \"total_assign_count\",\n",
    "    \"switch_ratio\",\n",
    "    \"discover_ratio\",\n",
    "    \"save_ratio\",\n",
    "    \"revisit_ratio\",\n",
    "    \"assign_ratio\",\n",
    "]\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = csv_file_path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a list to store columns that don't exist in the DataFrame\n",
    "columns_not_found = []\n",
    "\n",
    "print(f\"Attempting to remove {len(columns_to_remove)} colums\")\n",
    "# Remove the specified columns (if they exist)\n",
    "for column in columns_to_remove:\n",
    "    if column in df.columns:\n",
    "        df.drop(columns=column, inplace=True)\n",
    "    else:\n",
    "        columns_not_found.append(column)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "output_file_path = \"temp3_output_csv_file.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "\n",
    "if columns_not_found:\n",
    "    print(\n",
    "        len(columns_not_found),\n",
    "        \"columns not found in the input file. \\nSkipped the following:\",\n",
    "        columns_not_found,\n",
    "    )\n",
    "\n",
    "print(\"Success, output dimentions of the dataset:\", df.shape)\n",
    "print(f\"output to {output_file_path}. Don't forget to rename to 'datasetAll.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Size is 46 rows x 48 columns at last change (11/07/2023)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
