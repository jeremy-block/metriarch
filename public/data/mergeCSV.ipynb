{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introductions\n",
    "This code prepares a CSV file that the interface expects. \n",
    "\n",
    "1. This will take the series of Markov transition files for each interaction log dataset, and combine them into `temp1_merged_trasnsition data.csv`. \n",
    "2. This is then combined with the other metrics already in `datasetAll.csv` - creating `temp2_all_merged_data.csv`. \n",
    "3. We make a JSON file of preferences for any new metrics created by modifying the `datasetAll.json`. Note that this is the JSON version used by the visual interface to specify the names, descriptions and how many grid lines are used for each metric.\n",
    "4. Finally, we drop columns that are not meaningful or worth keeping by listing the available metric names and then dropping them by name. This step makes `temp3_output_csv_file.csv`.\n",
    "\n",
    "When scripts are finished running be sure to rename the output file `temp3_output_csv_file.csv` to `datasetAll.csv`!\n",
    "\n",
    "## 1. Merge the Transition probability data\n",
    "The set of transition probability files are CSV files that all have the same header, and just need to be combined into a single file. The files essentially are the likelihood that a user will conduct a specific event type. Essentially a table of Markov probabilities where each row is a user interaction session and the columns are the types of interaction transitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FileName</th>\n",
       "      <th>DataExplorationCounts</th>\n",
       "      <th>VisualExplorationCounts</th>\n",
       "      <th>InsightActionCounts</th>\n",
       "      <th>TheorizingCounts</th>\n",
       "      <th>DiscoveringCounts</th>\n",
       "      <th>AuditingCounts</th>\n",
       "      <th>OrganizingCounts</th>\n",
       "      <th>RecognizingCounts</th>\n",
       "      <th>TrackingCounts</th>\n",
       "      <th>...</th>\n",
       "      <th>DataExploringUnusual</th>\n",
       "      <th>VisualExploringUnusual</th>\n",
       "      <th>InsightActionUnusual</th>\n",
       "      <th>TheorizingUnusual</th>\n",
       "      <th>DiscoveringUnusual</th>\n",
       "      <th>AuditingUnusual</th>\n",
       "      <th>OrganizingUnusual</th>\n",
       "      <th>RecognizingUnusual</th>\n",
       "      <th>TrackingUnusual</th>\n",
       "      <th>TotalUnusual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arms_P1_InteractionsLogs.json</td>\n",
       "      <td>204.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>52.0</td>\n",
       "      <td>114.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.284738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arms_P2_InteractionsLogs.json</td>\n",
       "      <td>192.0</td>\n",
       "      <td>255.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>124.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.171729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arms_P3_InteractionsLogs.json</td>\n",
       "      <td>468.0</td>\n",
       "      <td>163.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>175.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.327957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.255302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arms_P4_InteractionsLogs.json</td>\n",
       "      <td>271.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>134.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>161.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>139.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.353293</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122302</td>\n",
       "      <td>0.217210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arms_P5_InteractionsLogs.json</td>\n",
       "      <td>310.0</td>\n",
       "      <td>205.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141935</td>\n",
       "      <td>0.117073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.218978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        FileName  DataExplorationCounts  \\\n",
       "0  Arms_P1_InteractionsLogs.json                  204.0   \n",
       "1  Arms_P2_InteractionsLogs.json                  192.0   \n",
       "2  Arms_P3_InteractionsLogs.json                  468.0   \n",
       "3  Arms_P4_InteractionsLogs.json                  271.0   \n",
       "4  Arms_P5_InteractionsLogs.json                  310.0   \n",
       "\n",
       "   VisualExplorationCounts  InsightActionCounts  TheorizingCounts  \\\n",
       "0                    144.0                 49.0             101.0   \n",
       "1                    255.0                 15.0             115.0   \n",
       "2                    163.0                 29.0             186.0   \n",
       "3                    196.0                 32.0             134.0   \n",
       "4                    205.0                  2.0             149.0   \n",
       "\n",
       "   DiscoveringCounts  AuditingCounts  OrganizingCounts  RecognizingCounts  \\\n",
       "0               80.0            67.0              67.0               52.0   \n",
       "1               50.0            41.0              37.0               27.0   \n",
       "2               68.0            80.0              24.0               33.0   \n",
       "3              167.0           161.0              51.0               46.0   \n",
       "4               29.0            19.0              48.0               37.0   \n",
       "\n",
       "   TrackingCounts  ...  DataExploringUnusual  VisualExploringUnusual  \\\n",
       "0           114.0  ...              0.254902                0.000000   \n",
       "1           124.0  ...              0.114583                0.000000   \n",
       "2           175.0  ...              0.170940                0.000000   \n",
       "3           139.0  ...              0.147601                0.000000   \n",
       "4           160.0  ...              0.141935                0.117073   \n",
       "\n",
       "   InsightActionUnusual  TheorizingUnusual  DiscoveringUnusual  \\\n",
       "0              0.306122           0.495050            0.450000   \n",
       "1              0.866667           0.043478            0.380000   \n",
       "2              0.241379           0.327957            1.000000   \n",
       "3              0.375000           0.305970            0.353293   \n",
       "4              1.000000           0.194631            1.000000   \n",
       "\n",
       "   AuditingUnusual  OrganizingUnusual  RecognizingUnusual  TrackingUnusual  \\\n",
       "0         0.477612           0.134328                 0.5         0.263158   \n",
       "1         0.317073           0.081081                 1.0         0.362903   \n",
       "2         0.162500           0.458333                 1.0         0.228571   \n",
       "3         0.198758           0.254902                 1.0         0.122302   \n",
       "4         1.000000           0.000000                 1.0         0.162500   \n",
       "\n",
       "   TotalUnusual  \n",
       "0      0.284738  \n",
       "1      0.171729  \n",
       "2      0.255302  \n",
       "3      0.217210  \n",
       "4      0.218978  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names to merge\n",
    "csv_files = [  # Replace with your file names\n",
    "    \"markov_1.csv\",\n",
    "    \"markov_2.csv\",\n",
    "    \"markov_3.csv\",\n",
    "    \"markov_4.csv\",\n",
    "    \"markov_5.csv\",\n",
    "]\n",
    "\n",
    "# Name of the common column used for merging\n",
    "merge_column_name = \"FileName\"  # Replace with the desired column name\n",
    "\n",
    "# Initialize an empty DataFrame as the base\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and merge\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # If it's the first file, set it as the base DataFrame\n",
    "    if merged_data.empty:\n",
    "        merged_data = df\n",
    "    else:\n",
    "        # Merge the current DataFrame with the base DataFrame based on the common column\n",
    "        merged_data = merged_data.merge(df, how=\"outer\")\n",
    "\n",
    "# Fill missing values with appropriate values (e.g., NaN or a specific value)\n",
    "merged_data = merged_data.fillna(\"\")\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv(\"temp1_merged_transitions_data.csv\", index=False)\n",
    "\n",
    "# Display the merged data\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Merge the unusual Transition types with the rest of the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>session</th>\n",
       "      <th>section</th>\n",
       "      <th>total_think_aloud_count</th>\n",
       "      <th>total_search_count</th>\n",
       "      <th>total_topic_change_count</th>\n",
       "      <th>total_mouse_hover_count</th>\n",
       "      <th>total_draging_count</th>\n",
       "      <th>total_open-doc_count</th>\n",
       "      <th>total_reading_count</th>\n",
       "      <th>total_highlight_count</th>\n",
       "      <th>...</th>\n",
       "      <th>DataExploringUnusual</th>\n",
       "      <th>VisualExploringUnusual</th>\n",
       "      <th>InsightActionUnusual</th>\n",
       "      <th>TheorizingUnusual</th>\n",
       "      <th>DiscoveringUnusual</th>\n",
       "      <th>AuditingUnusual</th>\n",
       "      <th>OrganizingUnusual</th>\n",
       "      <th>RecognizingUnusual</th>\n",
       "      <th>TrackingUnusual</th>\n",
       "      <th>TotalUnusual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Arms_P1_InteractionsLogs.json</td>\n",
       "      <td>Arms Dealing</td>\n",
       "      <td>137</td>\n",
       "      <td>82</td>\n",
       "      <td>10</td>\n",
       "      <td>143</td>\n",
       "      <td>169</td>\n",
       "      <td>134</td>\n",
       "      <td>159</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.306122</td>\n",
       "      <td>0.495050</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>0.477612</td>\n",
       "      <td>0.134328</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.263158</td>\n",
       "      <td>0.284738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Arms_P2_InteractionsLogs.json</td>\n",
       "      <td>Arms Dealing</td>\n",
       "      <td>69</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "      <td>275</td>\n",
       "      <td>132</td>\n",
       "      <td>91</td>\n",
       "      <td>233</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.380000</td>\n",
       "      <td>0.317073</td>\n",
       "      <td>0.081081</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.362903</td>\n",
       "      <td>0.171729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Arms_P3_InteractionsLogs.json</td>\n",
       "      <td>Arms Dealing</td>\n",
       "      <td>78</td>\n",
       "      <td>46</td>\n",
       "      <td>15</td>\n",
       "      <td>167</td>\n",
       "      <td>207</td>\n",
       "      <td>140</td>\n",
       "      <td>522</td>\n",
       "      <td>7</td>\n",
       "      <td>...</td>\n",
       "      <td>0.170940</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241379</td>\n",
       "      <td>0.327957</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.228571</td>\n",
       "      <td>0.255302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Arms_P4_InteractionsLogs.json</td>\n",
       "      <td>Arms Dealing</td>\n",
       "      <td>74</td>\n",
       "      <td>76</td>\n",
       "      <td>10</td>\n",
       "      <td>152</td>\n",
       "      <td>229</td>\n",
       "      <td>149</td>\n",
       "      <td>337</td>\n",
       "      <td>141</td>\n",
       "      <td>...</td>\n",
       "      <td>0.147601</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>0.305970</td>\n",
       "      <td>0.353293</td>\n",
       "      <td>0.198758</td>\n",
       "      <td>0.254902</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.122302</td>\n",
       "      <td>0.217210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Arms_P5_InteractionsLogs.json</td>\n",
       "      <td>Arms Dealing</td>\n",
       "      <td>32</td>\n",
       "      <td>66</td>\n",
       "      <td>11</td>\n",
       "      <td>264</td>\n",
       "      <td>139</td>\n",
       "      <td>239</td>\n",
       "      <td>173</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.141935</td>\n",
       "      <td>0.117073</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.194631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.162500</td>\n",
       "      <td>0.218978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         session       section  total_think_aloud_count  \\\n",
       "0  Arms_P1_InteractionsLogs.json  Arms Dealing                      137   \n",
       "1  Arms_P2_InteractionsLogs.json  Arms Dealing                       69   \n",
       "2  Arms_P3_InteractionsLogs.json  Arms Dealing                       78   \n",
       "3  Arms_P4_InteractionsLogs.json  Arms Dealing                       74   \n",
       "4  Arms_P5_InteractionsLogs.json  Arms Dealing                       32   \n",
       "\n",
       "   total_search_count  total_topic_change_count  total_mouse_hover_count  \\\n",
       "0                  82                        10                      143   \n",
       "1                  27                         6                      275   \n",
       "2                  46                        15                      167   \n",
       "3                  76                        10                      152   \n",
       "4                  66                        11                      264   \n",
       "\n",
       "   total_draging_count  total_open-doc_count  total_reading_count  \\\n",
       "0                  169                   134                  159   \n",
       "1                  132                    91                  233   \n",
       "2                  207                   140                  522   \n",
       "3                  229                   149                  337   \n",
       "4                  139                   239                  173   \n",
       "\n",
       "   total_highlight_count  ...  DataExploringUnusual  VisualExploringUnusual  \\\n",
       "0                     21  ...              0.254902                0.000000   \n",
       "1                      8  ...              0.114583                0.000000   \n",
       "2                      7  ...              0.170940                0.000000   \n",
       "3                    141  ...              0.147601                0.000000   \n",
       "4                      1  ...              0.141935                0.117073   \n",
       "\n",
       "   InsightActionUnusual  TheorizingUnusual  DiscoveringUnusual  \\\n",
       "0              0.306122           0.495050            0.450000   \n",
       "1              0.866667           0.043478            0.380000   \n",
       "2              0.241379           0.327957            1.000000   \n",
       "3              0.375000           0.305970            0.353293   \n",
       "4              1.000000           0.194631            1.000000   \n",
       "\n",
       "   AuditingUnusual  OrganizingUnusual  RecognizingUnusual  TrackingUnusual  \\\n",
       "0         0.477612           0.134328                 0.5         0.263158   \n",
       "1         0.317073           0.081081                 1.0         0.362903   \n",
       "2         0.162500           0.458333                 1.0         0.228571   \n",
       "3         0.198758           0.254902                 1.0         0.122302   \n",
       "4         1.000000           0.000000                 1.0         0.162500   \n",
       "\n",
       "   TotalUnusual  \n",
       "0      0.284738  \n",
       "1      0.171729  \n",
       "2      0.255302  \n",
       "3      0.217210  \n",
       "4      0.218978  \n",
       "\n",
       "[5 rows x 61 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# List of CSV file names to merge\n",
    "csv_files = [\n",
    "    \"./datasetAll_231117.csv\",\n",
    "    \"temp1_merged_transitions_data.csv\",\n",
    "]  # Replace with your 2 file names\n",
    "\n",
    "# Name of the common column used for merging\n",
    "left_column_name = \"session\"  # Replace with the desired column names\n",
    "right_column_name = \"FileName\"\n",
    "\n",
    "# Initialize an empty DataFrame as the base\n",
    "merged_data = pd.DataFrame()\n",
    "\n",
    "# Loop through each CSV file and merge\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    # If it's the first file, set it as the base DataFrame\n",
    "    if merged_data.empty:\n",
    "        merged_data = df\n",
    "    else:\n",
    "        # Merge the current DataFrame with the base DataFrame based on the common column\n",
    "        merged_data = merged_data.merge(\n",
    "            df, left_on=left_column_name, right_on=right_column_name, how=\"outer\"\n",
    "        )\n",
    "        merged_data.drop(\n",
    "            right_column_name, axis=1, inplace=True\n",
    "        )  # Remove right column since we have merged this.\n",
    "\n",
    "# Fill missing values with appropriate values (e.g., NaN or a specific value)\n",
    "merged_data = merged_data.fillna(\"0\")\n",
    "\n",
    "# Save the merged data to a new CSV file\n",
    "merged_data.to_csv(\"temp2_all_merged_data.csv\", index=False)\n",
    "\n",
    "# Display the merged data\n",
    "merged_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Modify or create a Config File to include any newly merged column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(input_csv_file, input_json_file, output_json_file):\n",
    "    # Initialize an empty dictionary to store the JSON data\n",
    "    json_data = {}\n",
    "\n",
    "    # Read the existing JSON data from the output file if it exists\n",
    "    try:\n",
    "        with open(input_json_file, 'r') as json_file:\n",
    "            json_data = json.load(json_file)\n",
    "    except FileNotFoundError:\n",
    "        pass\n",
    "\n",
    "    # Read the CSV file\n",
    "    with open(input_csv_file, 'r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "        # Iterate through the columns in the CSV file\n",
    "        for column_name in csv_reader.fieldnames:\n",
    "            # Check if the column name already exists in the JSON data\n",
    "            if column_name not in json_data:\n",
    "                json_data[f'{column_name}'] = {\n",
    "                    \"name\": column_name,\n",
    "                    \"unit\": \"\",\n",
    "                    \"description\": f\"a_written_description for {column_name}\",\n",
    "                    \"majorTicks\": 4,\n",
    "                    \"minorTicks\": 1,\n",
    "                    \"places\": 0\n",
    "                }\n",
    "\n",
    "    # Write the JSON data to the output file\n",
    "    with open(output_json_file, 'w') as json_file:\n",
    "        json.dump(json_data, json_file, indent=4)\n",
    "\n",
    "# Example usage:\n",
    "input_csv_file = 'temp2_all_merged_data.csv'\n",
    "input_json_file = 'datasetAll.json'\n",
    "output_json_file = input_json_file\n",
    "csv_to_json(input_csv_file, input_json_file, output_json_file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Drop columns with limited meaning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61 Column names in the CSV file:\n",
      "\"session\",\n",
      "\"section\",\n",
      "\"total_think_aloud_count\",\n",
      "\"total_search_count\",\n",
      "\"total_topic_change_count\",\n",
      "\"total_mouse_hover_count\",\n",
      "\"total_draging_count\",\n",
      "\"total_open-doc_count\",\n",
      "\"total_reading_count\",\n",
      "\"total_highlight_count\",\n",
      "\"total_connection_count\",\n",
      "\"total_create_note_count\",\n",
      "\"total_add_note_count\",\n",
      "\"think_aloud_ratio\",\n",
      "\"search_ratio\",\n",
      "\"topic_change_ratio\",\n",
      "\"mouse_hover_ratio\",\n",
      "\"draging_ratio\",\n",
      "\"open-doc_ratio\",\n",
      "\"reading_ratio\",\n",
      "\"highlight_ratio\",\n",
      "\"connection_ratio\",\n",
      "\"create_note_ratio\",\n",
      "\"add_note_ratio\",\n",
      "\"total_interaction_count\",\n",
      "\"total_duration\",\n",
      "\"repeat_searches\",\n",
      "\"prop_repeat_searches\",\n",
      "\"search_term_similarity\",\n",
      "\"search_time_std_dev\",\n",
      "\"search_open_overlap\",\n",
      "\"search_term_efficiency\",\n",
      "\"DataExplorationCounts\",\n",
      "\"VisualExplorationCounts\",\n",
      "\"InsightActionCounts\",\n",
      "\"TheorizingCounts\",\n",
      "\"DiscoveringCounts\",\n",
      "\"AuditingCounts\",\n",
      "\"OrganizingCounts\",\n",
      "\"RecognizingCounts\",\n",
      "\"TrackingCounts\",\n",
      "\"DataExploringUsual\",\n",
      "\"VisualExploringUsual\",\n",
      "\"InsightActionUsual\",\n",
      "\"TheorizingUsual\",\n",
      "\"DiscoveringUsual\",\n",
      "\"AuditingUsual\",\n",
      "\"OrganizingUsual\",\n",
      "\"RecognizingUsual\",\n",
      "\"TrackingUsual\",\n",
      "\"TotalUsual\",\n",
      "\"DataExploringUnusual\",\n",
      "\"VisualExploringUnusual\",\n",
      "\"InsightActionUnusual\",\n",
      "\"TheorizingUnusual\",\n",
      "\"DiscoveringUnusual\",\n",
      "\"AuditingUnusual\",\n",
      "\"OrganizingUnusual\",\n",
      "\"RecognizingUnusual\",\n",
      "\"TrackingUnusual\",\n",
      "\"TotalUnusual\",\n"
     ]
    }
   ],
   "source": [
    "if 'pd' not in globals():\n",
    "    import pandas as pd\n",
    "\n",
    "# get list of column names\n",
    "def get_column_names_from_csv(csv_file_path):\n",
    "    try:\n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(csv_file_path)\n",
    "\n",
    "        # Get the column names as a list\n",
    "        column_names = df.columns.tolist()\n",
    "\n",
    "        return column_names\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "csv_file_path = \"temp2_all_merged_data.csv\"  # Replace with the path to your CSV file\n",
    "column_names = get_column_names_from_csv(csv_file_path)\n",
    "\n",
    "if column_names is not None:\n",
    "    print(len(column_names), \"Column names in the CSV file:\")\n",
    "    for name in column_names:\n",
    "        print(f\"\\\"{name}\\\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempting to remove 82 colums\n",
      "66 columns not found in the input file. \n",
      "Skipped the following: ['total_initialized_count', 'total_query_results_count', 'total_read_count', 'total_playaudiofileinnewwindow_count', 'total_collapse_count', 'total_find_count', 'total_dispositionupdated_count', 'total_noteupdated_count', 'total_listening_count', 'total_createdocumentbucket_count', 'total_addtodocumentbucket_count', 'total_removefromdocumentbucket_count', 'total_tabs_to_questions_count', 'total_tabs_to_cap_count', 'total_edit_document_bucket_count', 'total_loaddocumentlist_count', 'total_show_count', 'total_getdocuments_count', 'total_answers_question_count', 'total_tabs_to_supplementary_count', 'total_tabs_to_bundle_count', 'total_reads_count', 'total_tabs_to_abreviations_count', 'total_answers_confidence_count', 'total_tabs_to_bundles_count', 'total_answer_count', 'total_initiate_count', 'total_custom_count', 'initialized_ratio', 'query_results_ratio', 'read_ratio', 'playaudiofileinnewwindow_ratio', 'collapse_ratio', 'find_ratio', 'dispositionupdated_ratio', 'noteupdated_ratio', 'listening_ratio', 'createdocumentbucket_ratio', 'addtodocumentbucket_ratio', 'removefromdocumentbucket_ratio', 'tabs_to_questions_ratio', 'tabs_to_cap_ratio', 'edit_document_bucket_ratio', 'loaddocumentlist_ratio', 'show_ratio', 'getdocuments_ratio', 'answers_question_ratio', 'tabs_to_supplementary_ratio', 'tabs_to_bundle_ratio', 'reads_ratio', 'tabs_to_abreviations_ratio', 'answers_confidence_ratio', 'tabs_to_bundles_ratio', 'answer_ratio', 'initiate_ratio', 'custom_ratio', 'total_switch_count', 'total_discover_count', 'total_save_count', 'total_revisit_count', 'total_assign_count', 'switch_ratio', 'discover_ratio', 'save_ratio', 'revisit_ratio', 'assign_ratio']\n",
      "Success, output dimentions of the dataset: (46, 45)\n",
      "output to temp3_output_csv_file.csv. Don't forget to rename to 'datasetAll.csv'\n"
     ]
    }
   ],
   "source": [
    "if \"pd\" not in globals():\n",
    "    import pandas as pd\n",
    "\n",
    "# Define the list of columns you want to remove\n",
    "columns_to_remove = [\n",
    "    \"total_topic_change_count\",\n",
    "    \"total_mouse_hover_count\",\n",
    "    \"total_draging_count\",\n",
    "    \"total_reading_count\",\n",
    "    \"total_highlight_count\",\n",
    "    \"total_connection_count\",\n",
    "    \"total_create_note_count\",\n",
    "    \"total_add_note_count\",\n",
    "    \"topic_change_ratio\",\n",
    "    \"mouse_hover_ratio\",\n",
    "    \"draging_ratio\",\n",
    "    \"reading_ratio\",\n",
    "    \"highlight_ratio\",\n",
    "    \"connection_ratio\",\n",
    "    \"create_note_ratio\",\n",
    "    \"add_note_ratio\",\n",
    "    \"total_initialized_count\",\n",
    "    \"total_query_results_count\",\n",
    "    \"total_read_count\",\n",
    "    \"total_playaudiofileinnewwindow_count\",\n",
    "    \"total_collapse_count\",\n",
    "    \"total_find_count\",\n",
    "    \"total_dispositionupdated_count\",\n",
    "    \"total_noteupdated_count\",\n",
    "    \"total_listening_count\",\n",
    "    \"total_createdocumentbucket_count\",\n",
    "    \"total_addtodocumentbucket_count\",\n",
    "    \"total_removefromdocumentbucket_count\",\n",
    "    \"total_tabs_to_questions_count\",\n",
    "    \"total_tabs_to_cap_count\",\n",
    "    \"total_edit_document_bucket_count\",\n",
    "    \"total_loaddocumentlist_count\",\n",
    "    \"total_show_count\",\n",
    "    \"total_getdocuments_count\",\n",
    "    \"total_answers_question_count\",\n",
    "    \"total_tabs_to_supplementary_count\",\n",
    "    \"total_tabs_to_bundle_count\",\n",
    "    \"total_reads_count\",\n",
    "    \"total_tabs_to_abreviations_count\",\n",
    "    \"total_answers_confidence_count\",\n",
    "    \"total_tabs_to_bundles_count\",\n",
    "    \"total_answer_count\",\n",
    "    \"total_initiate_count\",\n",
    "    \"total_custom_count\",\n",
    "    \"initialized_ratio\",\n",
    "    \"query_results_ratio\",\n",
    "    \"read_ratio\",\n",
    "    \"playaudiofileinnewwindow_ratio\",\n",
    "    \"collapse_ratio\",\n",
    "    \"find_ratio\",\n",
    "    \"dispositionupdated_ratio\",\n",
    "    \"noteupdated_ratio\",\n",
    "    \"listening_ratio\",\n",
    "    \"createdocumentbucket_ratio\",\n",
    "    \"addtodocumentbucket_ratio\",\n",
    "    \"removefromdocumentbucket_ratio\",\n",
    "    \"tabs_to_questions_ratio\",\n",
    "    \"tabs_to_cap_ratio\",\n",
    "    \"edit_document_bucket_ratio\",\n",
    "    \"loaddocumentlist_ratio\",\n",
    "    \"show_ratio\",\n",
    "    \"getdocuments_ratio\",\n",
    "    \"answers_question_ratio\",\n",
    "    \"tabs_to_supplementary_ratio\",\n",
    "    \"tabs_to_bundle_ratio\",\n",
    "    \"reads_ratio\",\n",
    "    \"tabs_to_abreviations_ratio\",\n",
    "    \"answers_confidence_ratio\",\n",
    "    \"tabs_to_bundles_ratio\",\n",
    "    \"answer_ratio\",\n",
    "    \"initiate_ratio\",\n",
    "    \"custom_ratio\",\n",
    "    \"total_switch_count\",\n",
    "    \"total_discover_count\",\n",
    "    \"total_save_count\",\n",
    "    \"total_revisit_count\",\n",
    "    \"total_assign_count\",\n",
    "    \"switch_ratio\",\n",
    "    \"discover_ratio\",\n",
    "    \"save_ratio\",\n",
    "    \"revisit_ratio\",\n",
    "    \"assign_ratio\",\n",
    "]\n",
    "\n",
    "# Load the CSV file into a DataFrame\n",
    "file_path = csv_file_path\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Create a list to store columns that don't exist in the DataFrame\n",
    "columns_not_found = []\n",
    "\n",
    "print(f\"Attempting to remove {len(columns_to_remove)} colums\")\n",
    "# Remove the specified columns (if they exist)\n",
    "for column in columns_to_remove:\n",
    "    if column in df.columns:\n",
    "        df.drop(columns=column, inplace=True)\n",
    "    else:\n",
    "        columns_not_found.append(column)\n",
    "\n",
    "# Save the modified DataFrame back to a new CSV file\n",
    "output_file_path = \"temp3_output_csv_file.csv\"\n",
    "df.to_csv(output_file_path, index=False)\n",
    "\n",
    "\n",
    "if columns_not_found:\n",
    "    print(\n",
    "        len(columns_not_found),\n",
    "        \"columns not found in the input file. \\nSkipped the following:\",\n",
    "        columns_not_found,\n",
    "    )\n",
    "\n",
    "print(\"Success, output dimentions of the dataset:\", df.shape)\n",
    "print(f\"output to {output_file_path}. Don't forget to rename to 'datasetAll.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Expected Size is 46 rows x 45 columns at last change (12/03/2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
